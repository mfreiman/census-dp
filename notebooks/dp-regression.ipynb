{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy preserving logistic regression\n",
    "#### A post-processing example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this notebook we give examples of performing regression.\n",
    "\n",
    "Several common formally private noise injection methods depend upon the concept of global sensitivity: how much can a given output change due to adding or deleting a single person across all possible datasets we could observe?\n",
    "\n",
    "Regression poses a problem for these methods. If we consider a simple ordinary least squares model with a single predictor, we can imagine scenarios where adding or deleting a single person can have a marked effect upon the slope of the regression line. In many cases, this effect can be unbounded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, zipfile, io\n",
    "import sklearn\n",
    "import random\n",
    "from typing import Union\n",
    "import statsmodels.api as sm\n",
    "\n",
    "if 'z' not in locals():\n",
    "    r = requests.get('https://www2.census.gov/programs-surveys/acs/data/pums/2017/5-Year/csv_pla.zip')\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extract('psam_p22.csv')\n",
    "\n",
    "keepcols = ['PUMA','RACWHT','PINCP','AGEP','SCHL','MIGPUMA','MIGSP']\n",
    "pa = pd.read_csv(\"psam_p22.csv\", usecols=keepcols)\n",
    "\n",
    "#getting data\n",
    "pa.query('PUMA==2400', inplace=True)\n",
    "\n",
    "def migrecode(migpuma):\n",
    "    if pd.isnull(migpuma):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def agerecode(age):\n",
    "    if age < 18:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def schlrecode(schl):\n",
    "    if schl < 18:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "pa['MIGRATED']=pa.MIGPUMA.apply(migrecode)\n",
    "pa['ADULT']=pa.AGEP.apply(agerecode)\n",
    "pa['COLLEGE']=pa.SCHL.apply(schlrecode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression as Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in data from Louisiana and keep data from PUMA 2400 containing New Orleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a little bit of the microdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUMA</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MIGPUMA</th>\n",
       "      <th>MIGSP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>RACWHT</th>\n",
       "      <th>MIGRATED</th>\n",
       "      <th>ADULT</th>\n",
       "      <th>COLLEGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2400</td>\n",
       "      <td>30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2400</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2400</td>\n",
       "      <td>56</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2400</td>\n",
       "      <td>57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2400</td>\n",
       "      <td>26</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PUMA  AGEP  SCHL  MIGPUMA  MIGSP    PINCP  RACWHT  MIGRATED  ADULT  \\\n",
       "207  2400    30  18.0   2390.0   22.0  35000.0       0         1      1   \n",
       "208  2400     7   4.0      NaN    NaN      NaN       0         0      0   \n",
       "275  2400    56  22.0      NaN    NaN  68000.0       0         0      1   \n",
       "276  2400    57  20.0      NaN    NaN  58700.0       0         0      1   \n",
       "382  2400    26  12.0      NaN    NaN  18000.0       1         0      1   \n",
       "\n",
       "     COLLEGE  \n",
       "207        1  \n",
       "208        0  \n",
       "275        1  \n",
       "276        1  \n",
       "382        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa.head()\n",
    "#print(pa.ADULT.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use three binary predictor variables: whether the person is white (already in the data), whether the person is an adult and whether the person has any education beyond high school (The last two constructed above). We want to predict whether the person migrated from another PUMA.\n",
    "\n",
    "We begin by calculating the non-noisy regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416755\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: -0.194   \n",
      "Dependent Variable: MIGRATED         AIC:              7180.8469\n",
      "Date:               2019-09-03 11:47 BIC:              7202.0282\n",
      "No. Observations:   8608             Log-Likelihood:   -3587.4  \n",
      "Df Model:           2                LL-Null:          -3003.9  \n",
      "Df Residuals:       8605             LLR p-value:      1.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     6.0000                                      \n",
      "-----------------------------------------------------------------\n",
      "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "-----------------------------------------------------------------\n",
      "RACWHT      -0.3559    0.0653   -5.4504  0.0000  -0.4839  -0.2279\n",
      "ADULT       -1.8148    0.0549  -33.0535  0.0000  -1.9224  -1.7072\n",
      "COLLEGE     -0.2615    0.0678   -3.8539  0.0001  -0.3945  -0.1285\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#feature selection \n",
    "#TODO: change Y value to rent or mortage\n",
    "X = pa[['RACWHT','ADULT','COLLEGE']]\n",
    "y = pa.MIGRATED\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to implement the Laplace mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplace_mech(mu: Union[float, np.ndarray], epsilon: int, sensitivity: float = 1.0):\n",
    "    \"\"\"\n",
    "    Implementation of the Laplace Mechanism\n",
    "\n",
    "    Args:\n",
    "      mu (float or numpy array): the true answer\n",
    "      epsilon (int): the privacy budget\n",
    "      sensitivity (float): the global sensitivity of the query\n",
    "    \"\"\"\n",
    "    eps = epsilon/float(sensitivity)\n",
    "    scale = 1/eps\n",
    "    np_shape = np.shape(mu)\n",
    "    shape = None if np_shape == () else np_shape\n",
    "    z = np.random.laplace(0.0, scale=scale, size=shape)\n",
    "    return mu + z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running the regression and adding noise to the coefficients, we do the four-way cross-tabulation of the predictor variables and the response variable. We then add noise to the cross-tab using the Laplace mechanism and an epsilon of 0.25. This is considered the noisy data and is used for the ROC curve. Below, we show the original four-way contingency table and a noisy four-way contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACWHT  ADULT  COLLEGE  MIGRATED\n",
      "0       0      0        0            984\n",
      "                        1            125\n",
      "               1        0            161\n",
      "                        1             23\n",
      "        1      0        0           1806\n",
      "                        1            193\n",
      "               1        0           2296\n",
      "                        1            220\n",
      "1       0      0        0            358\n",
      "                        1             37\n",
      "               1        0             95\n",
      "                        1             18\n",
      "        1      0        0            348\n",
      "                        1             49\n",
      "               1        0           1603\n",
      "                        1            292\n",
      "dtype: int64\n",
      "RACWHT  ADULT  COLLEGE  MIGRATED\n",
      "0       0      0        0            985.59\n",
      "                        1            122.97\n",
      "               1        0            157.91\n",
      "                        1             19.60\n",
      "        1      0        0           1807.38\n",
      "                        1            191.52\n",
      "               1        0           2295.81\n",
      "                        1            215.40\n",
      "1       0      0        0            358.80\n",
      "                        1             29.28\n",
      "               1        0             90.80\n",
      "                        1             15.43\n",
      "        1      0        0            347.33\n",
      "                        1             49.54\n",
      "               1        0           1602.46\n",
      "                        1            292.14\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tab=pd.crosstab(pa.MIGRATED, [pa.RACWHT, pa.ADULT, pa.COLLEGE])\n",
    "#tab=pd.crosstab(pa.MIGRATED, [pa.RACWHT, pa.ADULT, pa.COLLEGE]).unstack()\n",
    "noise = laplace_mech(np.zeros(tab.shape), 0.25, 1.0)\n",
    "noisy_tab = tab + noise\n",
    "print(tab.unstack())\n",
    "print(noisy_tab.unstack().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_l1_laplace(epsilon, mu, sensitivity=1.0, n=1000):\n",
    "    \"\"\"Takes the average error of the laplace mechanism on an array over n samples.\n",
    "  　\n",
    "    Args:\n",
    "      epsilon (int): the privacy budget\n",
    "      mu (float or numpy array): the true answer\n",
    "      n (int): number of samples\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        noisy_arr = laplace_mech(mu, epsilon)\n",
    "        accuracy = 1 - (np.linalg.norm(noisy_arr-mu, 1)/(2*mu.sum()))\n",
    "        total += accuracy\n",
    "    return total/n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have added noise to the counts, the differential privacy is done. These counts (unrounded) are considered protected, and you can do anything you want with them (including release them as shown above) without using additional privacy loss budget. We will turn them back into microdata and do the desired regression, but everything from here on is post-processing. As such, the ROC curve is calculated on the unrounded noisy counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMxKcSIxM7NSnEjMzKyU/w/yWfzAHXi3PwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x257b2266e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_arr = tab.unstack().values\n",
    "accuracy_df = pd.DataFrame()\n",
    "eps_range = np.arange(0,1,.1)\n",
    "accuracy_df['Privacy Loss (ϵ)'] = eps_range\n",
    "#print(avg_l1_laplace(1, orig_arr))\n",
    "\n",
    "accuracy_df['Accuracy'] = [avg_l1_laplace(x, orig_arr) for x in eps_range]\n",
    "accuracy_df.plot.scatter('Privacy Loss (ϵ)', 'Accuracy',ylim=[.99,1])\n",
    "plt.title('Trade-Off Between Privacy Loss and Accuracy')\n",
    "plt.style.use('seaborn-paper')\n",
    "#accuracy_df.set_ylim([.99,1])\n",
    "plt.savefig('out/fig.png',facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', ransparent=False, bbox_inches=None, pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now round each cell in the noisy table to the nearest nonnegative integer. From this, we can reconstruct a noisy microdata set. This step and anything subsequently done to the data are post-processing.\n",
    "\n",
    "Since we have the noisy counts of the cross tabulation of RACWHT, ADULT, COLLEGE and MIGRATED, we can create a scaled-down microdata set where each record has only these four variables. For example, if the noisy count of how many people have 0 for all variables is 982.07, we round to 982 and then we create 982 microdata records with this combination of variables. We then repeat for all other combinations of different possible values for the four variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_process(tab_values: np.array):\n",
    "    tab_values[tab_values < 0] = 0\n",
    "    return tab_values.round().astype('int')\n",
    "\n",
    "def reconstruct(noisy_tab):\n",
    "    noisy_unstack = noisy_tab.unstack()\n",
    "    reps = post_process(noisy_unstack.values)\n",
    "    colnames = noisy_unstack.index.names\n",
    "    combinations = noisy_unstack.index.get_values()\n",
    "    combinations = np.matrix([list(tup) for tup in combinations])\n",
    "    noisy_microdata = pd.DataFrame(np.repeat(combinations, reps, axis=0),\n",
    "                                  columns=colnames)\n",
    "    return noisy_microdata\n",
    "\n",
    "noisy_microdata = reconstruct(noisy_tab)\n",
    "#print(noisy_microdata.ADULT.value_counts())\n",
    "#print(post_process(noisy_tab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the regression on the noisy microdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414080\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: -0.199   \n",
      "Dependent Variable: MIGRATED         AIC:              7139.7703\n",
      "Date:               2019-08-28 12:10 BIC:              7160.9537\n",
      "No. Observations:   8614             Log-Likelihood:   -3566.9  \n",
      "Df Model:           2                LL-Null:          -2975.4  \n",
      "Df Residuals:       8611             LLR p-value:      1.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     6.0000                                      \n",
      "-----------------------------------------------------------------\n",
      "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "-----------------------------------------------------------------\n",
      "RACWHT      -0.3575    0.0654   -5.4644  0.0000  -0.4858  -0.2293\n",
      "ADULT       -1.8139    0.0551  -32.9321  0.0000  -1.9219  -1.7060\n",
      "COLLEGE     -0.2898    0.0684   -4.2403  0.0000  -0.4238  -0.1559\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = noisy_microdata[['RACWHT','ADULT','COLLEGE']]\n",
    "y = noisy_microdata.MIGRATED\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This output is close to the original output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
